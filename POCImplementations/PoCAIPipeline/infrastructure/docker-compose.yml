version: '3.8'

services:
  # Redis for feature store
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

  # MLflow Tracking Server
  mlflow:
    build:
      context: .
      dockerfile: Dockerfile.mlflow
    ports:
      - "5000:5000"
    environment:
      - MLFLOW_BACKEND_STORE_URI=sqlite:///mlflow.db
      - MLFLOW_DEFAULT_ARTIFACT_ROOT=/mlflow/artifacts
    volumes:
      - mlflow_data:/mlflow
      - ./models:/models
    depends_on:
      - redis

  # Feast Feature Server
  feast:
    image: feastdev/feast-server:latest
    ports:
      - "6566:6566"
    environment:
      - FEAST_CONFIG=/feature_repo/feature_store.yaml
    volumes:
      - ../feature_repo:/feature_repo
    depends_on:
      - redis

  # Inference API
  inference-api:
    build:
      context: ..
      dockerfile: infrastructure/Dockerfile.inference
    ports:
      - "8000:8000"
    environment:
      - OCR_MODEL_PATH=/models/ocr_lora
      - DOCUMENT_MODEL_PATH=/models/document_lora
      - FEATURE_STORE_ENABLED=true
      - FEATURE_STORE_REPO_PATH=/feature_repo
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    volumes:
      - ./models:/models
      - ../feature_repo:/feature_repo
    depends_on:
      - redis
      - mlflow
      - feast

volumes:
  redis_data:
  mlflow_data:

