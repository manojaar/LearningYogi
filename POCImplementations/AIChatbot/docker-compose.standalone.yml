version: '3.8'

# Standalone microservice deployment for integration into other docker-compose files
# Copy this service definition into your main docker-compose.yml

services:
  ai-chatbot:
    build:
      context: ./AIChatbot/backend/python
      dockerfile: Dockerfile
    container_name: ai-chatbot
    ports:
      - "${CHATBOT_PORT:-9000}:9000"
    environment:
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - CHATBOT_PROVIDER_PREFERENCE=${CHATBOT_PROVIDER_PREFERENCE:-claude,openai,local}
      - CHATBOT_CLAUDE_MODEL=${CHATBOT_CLAUDE_MODEL:-claude-3-haiku-20240307}
      - CHATBOT_OPENAI_MODEL=${CHATBOT_OPENAI_MODEL:-gpt-3.5-turbo}
      - LOCAL_LLM_URL=${LOCAL_LLM_URL:-http://localhost:11434}
      - LOCAL_LLM_MODEL=${LOCAL_LLM_MODEL:-llama2}
      - CHATBOT_ENABLE_CONTEXT=${CHATBOT_ENABLE_CONTEXT:-true}
      - POC_DB_URL=${POC_DB_URL:-./data/database/app.db}
      - KNOWLEDGE_BASE_PATH=/config/knowledge_base
    volumes:
      - ./AIChatbot/config:/config:ro
      - ./data:/data:ro  # Mount POC database if needed
    networks:
      - default
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

